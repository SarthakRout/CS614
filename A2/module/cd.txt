#include <linux/module.h>
#include <linux/kernel.h>
#include <linux/mm.h>
#include <linux/mm_types.h>
#include <linux/kprobes.h>
#include <linux/file.h>
#include <linux/fs.h>
#include <linux/path.h>
#include <linux/slab.h>
#include <linux/dcache.h>
#include <linux/sched.h>
#include <linux/uaccess.h>
#include <linux/fs_struct.h>
#include <asm/tlbflush.h>
#include <linux/device.h>
#include <linux/kthread.h>
#include <linux/delay.h>
#include <linux/hugetlb.h>
#include <linux/vmalloc.h>
#include <linux/sched/task_stack.h>
#include<linux/mmap_lock.h>
#include<linux/mutex.h>

#include "btplus.h"

#define HOOK_SYSCALL_NAME "sys_munmap"

static int major;
atomic_t device_opened;
static struct class *demo_class;
struct device *demo_device;

struct kobject *cs614_kobject;
unsigned promote = 0;

static ssize_t sysfs_show(struct kobject *kobj,
						  struct kobj_attribute *attr, char *buf);
static ssize_t sysfs_store(struct kobject *kobj,
						   struct kobj_attribute *attr, const char *buf, size_t count);

struct kobj_attribute sysfs_attr;

struct address
{
	unsigned long from_addr;
	unsigned long to_addr;
};

struct input
{
	unsigned long addr;
	unsigned length;
	struct address *buff;
};

unsigned long (*magic)(const char *name);


unsigned long lookup_kallsyms_lookup_name(void) {
    struct kprobe kp;
	
    unsigned long addr;
    
    memset(&kp, 0, sizeof(struct kprobe));
    kp.symbol_name = "kallsyms_lookup_name";
    if (register_kprobe(&kp) < 0) {
        return 0;
    }
    addr = (unsigned long)kp.addr;
    unregister_kprobe(&kp);
    return addr;
}

static int device_open(struct inode *inode, struct file *file)
{
	atomic_inc(&device_opened);
	try_module_get(THIS_MODULE);
	printk(KERN_INFO "Device opened successfully\n");
	return 0;
}

static int device_release(struct inode *inode, struct file *file)
{
	atomic_dec(&device_opened);
	module_put(THIS_MODULE);
	printk(KERN_INFO "Device closed successfully\n");

	return 0;
}

static ssize_t device_read(struct file *filp,
						   char *buffer,
						   size_t length,
						   loff_t *offset)
{
	printk("read called\n");
	return 0;
}

static ssize_t
device_write(struct file *filp, const char *buff, size_t len, loff_t *off)
{

	printk("write called\n");
	return 8;
}

pte_t* return_pfn(struct mm_struct * mm, unsigned long addr){
	// unsigned long * pgd,p4d,pud,pmd,ptep,pte;
	pgd_t*pgd;
	p4d_t* p4d;
	pud_t* pud;
	pmd_t * pmd;
	pte_t * ptep;
	pte_t pte;



	pgd = pgd_offset(mm, addr);
	if (pgd_none(*pgd) || pgd_bad(*pgd)){
    printk("Invalid pgd");
    return NULL;
	}
	// printk("Pgd*: %p\n",pgd);
	// printk("Pgd: %lx\n",pgd->pgd);

	p4d = p4d_offset(pgd, addr);
	if (p4d_none(*p4d) || p4d_bad(*p4d)){
		printk("Invalid p4d");
		return NULL;
	}

	// printk("P4D*: %p\n",p4d);
	// printk("P4D*: %lx\n",p4d->p4d);

	pud = pud_offset(p4d, addr);
	if (pud_none(*pud) || pud_bad(*pud)){
		printk("Invalid pud");
		return NULL;
	}
	// printk("PUD*: %p\n",pud);
	// printk("PUD: %lx\n",pud->pud);


	pmd = pmd_offset(pud, addr);
	if (pmd_none(*pmd) || pmd_bad(*pmd)){
		printk("Invalid pmd");
		return NULL;
	}

	// printk("Pmd*: %p\n",pmd);
	// printk("Pmd: %lx\n",pmd->pmd);

	ptep = pte_offset_map(pmd, addr);
	if (!ptep){
		printk("Invalid ptep");
		return NULL;
	}

	// printk("Ptep: %p\n",ptep);
	 pte = *ptep;

	if (pte_present(pte)){
		// printk("pte_set_flags");
		// printk("PTEP: %p\n",ptep);
		// printk("pte is present and pte : %lx\n",ptep->pte);
		return ptep;
		
	}	

	return NULL;

}

unsigned long (*my_move_page_tables) (struct vm_area_struct * ovma, unsigned long old_addr,  struct vm_area_struct * nvma, unsigned long to_addr, unsigned long length, bool val);

int (*my_do_munmap) (struct mm_struct *, unsigned long, size_t, struct list_head *uf);

struct vm_area_struct*  (*my_copy_vma) (struct vm_area_struct **vmap, unsigned long addr, unsigned long len, pgoff_t pgoff, bool* need_rmap_locks);

int my_mremap(struct vm_area_struct * ovma, unsigned long to_addr){
	int ret = 0;
	unsigned long length = 0, moved_len;
	struct vm_area_struct * nvma;
	bool need_rmap_locks;
	LIST_HEAD(uf_unmap);

	length = (ovma->vm_end - ovma->vm_start);
	nvma = (*my_copy_vma)(&ovma, to_addr, length, ovma->vm_pgoff, &need_rmap_locks);
	if (!nvma) {
		return -1;
	}
	moved_len = (*my_move_page_tables)(ovma, ovma->vm_start, nvma, to_addr, length, false);
	printk(KERN_INFO "Moved page tables with moved_len = %ld and length = %ld \n", moved_len, length);
	if(moved_len != length){
		return -1;
	}
	else if(ovma->vm_ops && ovma->vm_ops->mremap){
		ovma->vm_ops->mremap(nvma);
	}
	(*my_do_munmap)(ovma->vm_mm, ovma->vm_start, length, &uf_unmap);
	__flush_tlb_all();
	return ret;
}



static struct task_struct * kthread_task;

unsigned long HUGE_PAGE_SIZE = (1ULL<<21);
unsigned long HUGE_PAGE_SHIFT = 21;

static void remap_huge_page(struct mm_struct * mm, unsigned long addr, unsigned long pfn){
	pgd_t *pgd_off = pgd_offset(mm, addr);
	p4d_t *p4d_off = p4d_offset(pgd_off, addr);
	pud_t *pud_off = pud_offset(p4d_off, addr);
	pmd_t *pmd_off = pmd_offset(pud_off, addr);

	printk(KERN_INFO "In remap_huge_page mm: %p, addr: %lx, pfn: %lx", mm, addr, pfn);
	// update pmd to point to huge page
	*pmd_off = __pmd(pfn * PAGE_SIZE | _PAGE_PRESENT | _PAGE_RW | _PAGE_USER | _PAGE_PSE);
	printk(KERN_INFO "PMD: %lx", pmd_off->pmd);
}

static void do_promote(struct mm_struct * mm, unsigned long sp){
	struct vm_area_struct * vma;
	unsigned long sz, addr;
	unsigned long vm_start, vm_end;
	VMA_ITERATOR(vmi, mm, 0);
	printk(KERN_INFO "In do_promote mm: %p, sp: %lx\n", mm, sp);
	printk(KERN_INFO "MM PID: %p, %ld\n", mm->pgd, mm->total_vm);

	for_each_vma(vmi, vma){

		sz = vma->vm_end - vma->vm_start;
		printk(KERN_INFO "START: %lx, END: %lx DIFF:%lx\n", vma->vm_start, vma->vm_end, sz);
		if(sp >= vma->vm_start && sp < vma->vm_end){
			continue;
		}
		if(sz < HUGE_PAGE_SIZE){
			printk("Size of vma is less than 2MB. Skipping this vma.\n");
			continue;
		}
		if (vma->vm_flags & VM_HUGEPAGE) {
            printk("Huge page already exists for this vma. Skipping this vma.\n");
			continue;
		}
		printk(KERN_INFO "Starting to promote vma: %lx, %lx\n", vma->vm_start, vma->vm_end);

		if(vma->vm_start % (1<<21)){
			vm_start = (vma->vm_start + (1<<21)) & ~((1<<21) - 1);
		}
		else{
			vm_start = vma->vm_start;
		}
		if(vma->vm_end % (1<<21)){
			vm_end = (vma->vm_end) & ~((1<<21) - 1);
		}
		else{
			vm_end = vma->vm_end;
		}
		printk(KERN_INFO "vm_start: %lx, vm_end: %lx\n", vm_start, vm_end);
		for(addr = vm_start; addr < vm_end; addr += HUGE_PAGE_SIZE){

			struct page *page = NULL;
            unsigned long pfn;
			void * pagad;
			bool all_page_allocated = true;
			

			if(addr + HUGE_PAGE_SIZE > vm_end){
				printk("Last page of vma. Skipping this page.\n");
				break;
			}

			// Check whether all the pages in this region are allocated
			for(int i = 0; i<512; i++){
				pte_t * ptep = return_pfn(mm, addr + i * (1<<12));
				// printk(KERN_INFO "Old Page: %ld, %lu\n", (addr + i * (1<<12)), ( (ptep == NULL) ? 0 :ptep->pte));
				if(ptep == NULL){
					printk(KERN_INFO "Skipping this region\n");
					all_page_allocated = false;
					break;
				}
			}
			printk(KERN_INFO "All page allocated: %d\n", all_page_allocated);
			if(!all_page_allocated){
				continue;
			}
			

            // Allocate a 2MB page
            page = alloc_pages(GFP_USER | __GFP_COMP | __GFP_ZERO, HPAGE_SHIFT - PAGE_SHIFT);
            if (!page) {
                printk(KERN_ERR "Failed to allocate a 2MB page\n");
                continue;
            }


            // Get the physical page frame number (pfn) of the allocated page
            pfn = page_to_pfn(page);
			printk(KERN_INFO "PFN: %lx\n", pfn);

            // Copy contents from original page frame to the new page frame
			pagad = page_address(page);
			for(int i = 0; i<512; i++){
				pte_t * ptep = return_pfn(mm, addr + i * (1<<12));
				if(ptep != NULL){
					// printk(KERN_INFO "New Page: %p Old Page: %lx\n", (pagad + i * (1<<12)), (addr + i * (1<<12)));
					memcpy((void *)(pagad + i * (1<<12)), (void *)(addr + i * (1<<12)), (1<<12));
				}
			}			
			printk(KERN_INFO "Copied contents\n");

            // Remap current vma address to new physical page range
            // new_pfn = pfn + ((addr - vma->vm_start) >> HUGE_PAGE_SHIFT);
			remap_huge_page(mm, addr, pfn);
            // remap_pfn_range(vma, addr, pfn, HUGE_PAGE_SIZE, vma->vm_page_prot);
			vma->vm_flags |= 0x20000000;
			printk("pid : %d vmflags: %lx\n", current->pid, vma->vm_flags);
		}
	}
	printk(KERN_INFO "Promotion done\n");
	__flush_tlb_all();
	// mmap_write_unlock(mm);
}

struct inp {
	struct mm_struct * mm;
	unsigned long sp;
};

static int promote_pages(void * data){
	struct inp * ip = (struct inp * ) data;
	
	while(!kthread_should_stop()){
		if(promote==1){
			printk(KERN_INFO "Promote: %d\n", promote);
			printk(KERN_INFO "Promoting pages with mm: %p, sp: %lx\n", ip->mm, ip->sp);
			// mmap_write_lock(ip->mm);
			// do_promote(ip->mm, ip->sp);
			// mmap_write_unlock(ip->mm);
		}
		msleep(1000);
	}
	return 0;
}

long compact_vma(struct mm_struct *mm, unsigned long vma_addr, unsigned length, struct address *buff){
	struct vm_area_struct * vm_addr;
	struct vm_area_struct * vm_area = NULL;
	unsigned long addr = vma_addr, pfn, glob_addr = vma_addr;

	int ret =-1, count_allocated = 0;
	pte_t ** pfn_array = (pte_t **)kzalloc(sizeof(pte_t) * length, GFP_KERNEL);
	struct address *ker_buff = (struct address *)kzalloc(sizeof(struct address) * length, GFP_KERNEL);
	VMA_ITERATOR(vmi, mm, 0);
	
	mmap_read_lock(mm);
	for_each_vma(vmi, vm_addr) {
			if((vm_addr->vm_start <= vma_addr && vm_addr->vm_end >= vma_addr)){
				vm_area = vm_addr;
				break;
			}
			printk("Start of a vma:%lu  End of the vma:%lu Size of each vma : %lu\n",vm_addr->vm_start,vm_addr->vm_end, vm_addr->vm_end - vm_addr->vm_start);
		
	}
	mmap_read_unlock(mm);

	for(int t = 0; t < length; t++){
		pfn_array[t] = return_pfn(mm, addr);
		addr += PAGE_SIZE;
	}

	addr = vma_addr;
	for(int i = 0; i < length; i++){
		ker_buff[i].from_addr = ker_buff[i].to_addr = vma_addr + i * PAGE_SIZE;
		if(pfn_array[i] != NULL){
			count_allocated++;
		}
	}

	while(pfn_array[(glob_addr - vma_addr) >> PAGE_SHIFT] != NULL){
		glob_addr += PAGE_SIZE;  
	}


	addr = vma_addr + count_allocated * PAGE_SIZE;
	for(int t = count_allocated; t < length; t++){
		if(pfn_array[t] != NULL){
			pfn = (pfn_array[t]->pte << 1) >> 13;
			down_write(&(mm->mmap_lock));
			ret = remap_pfn_range(vm_area, glob_addr, pfn, PAGE_SIZE, vm_area->vm_page_prot);
			up_write(&(mm->mmap_lock));
			ker_buff[t].to_addr = glob_addr;
			ker_buff[(glob_addr - vma_addr) >> PAGE_SHIFT].to_addr = vma_addr + t * PAGE_SIZE;
			while(pfn_array[(glob_addr - vma_addr) >> PAGE_SHIFT] != NULL){
				glob_addr += PAGE_SIZE;  
			}
		}
	}

	// for(int i = 0; i<20; i++){
	// 	printk("Old Addr: %lx, New Addr: %lx\n", ker_buff[i].from_addr, ker_buff[i].to_addr);
	// }

	__flush_tlb_all();
	printk("User buffer addr: %lx", (unsigned long)buff);
	if(copy_to_user(buff, ker_buff, sizeof(struct address) * length)){
	    pr_err("COMPACT VMA read error 1\n");
		return ret;
	} 

	return 0;
}

long device_ioctl(struct file *file,
				  unsigned int ioctl_num,
				  unsigned long ioctl_param)
{
	int ret = 0; // on failure return -1
	struct address *buff = NULL;
	unsigned long vma_addr = 0;
	unsigned long to_addr = 0;
	unsigned length = 0, delta = 0;
	struct input *ip;
	struct inp * kp;
	// unsigned index = 0;
	struct address temp;
	struct pt_regs * regs;


	struct vm_area_struct *vma, *ovma = NULL;
	struct mm_struct *mm = current->mm;
	VMA_ITERATOR(vmi, mm, 0);

	/*
	 * Switch according to the ioctl called
	 */
	switch (ioctl_num){

	case IOCTL_MVE_VMA_TO:
		buff = (struct address *)vmalloc(sizeof(struct address));
		printk("move VMA at a given address");
		if (copy_from_user(buff, (char *)ioctl_param, sizeof(struct address)))
		{
			pr_err("MVE_VMA address write error\n");
			return -1;
		}
		vma_addr = buff->from_addr;
		to_addr = buff->to_addr;
		vfree(buff);
		// printk("address from :%lx, to:%lx \n", vma_addr, to_addr);
		mmap_read_lock(mm);
		for_each_vma(vmi, vma)
		{
			// printk(KERN_INFO "START: %lx, END: %lx\n", vma->vm_start, vma->vm_end);
			if (vma->vm_start <= vma_addr && vma_addr < vma->vm_end)
			{
				ovma = vma;
				to_addr -= vma_addr - ovma->vm_start;
				// printk("Found here\n");
			}
		}
		mmap_read_unlock(mm);
		if(ovma == NULL){
			return -1;
		}
		mmap_write_lock(mm);
		ret = my_mremap(ovma, to_addr);
		mmap_write_unlock(mm);
		return ret;

	case IOCTL_MVE_VMA:
		buff = (struct address *)vmalloc(sizeof(struct address));
		printk("move VMA to available hole address");
		if (copy_from_user(buff, (char *)ioctl_param, sizeof(struct address)))
		{
			pr_err("MVE_VMA address write error\n");
			return -1;
		}
		vma_addr = buff->from_addr;
		printk("VMA address :%lx \n", vma_addr);

		// find old VMA
		mmap_read_lock(mm);
		for_each_vma(vmi, vma)
		{
			printk( "START: %lx, END: %lx\n", vma->vm_start, vma->vm_end);
			if (vma->vm_start <= vma_addr && vma_addr < vma->vm_end) {
				ovma = vma;
			}
		}
		mmap_read_unlock(mm);
		if(ovma == NULL){
			vfree(buff);
			return -1;
		}

		// Find to_Addr

		to_addr =  get_unmapped_area(ovma->vm_file, 0, (ovma->vm_end - ovma->vm_start), ovma->vm_pgoff, 0);
		if(IS_ERR_VALUE(to_addr)){
			vfree(buff);
			return -1;
		}
		else{
			delta = vma_addr - ovma->vm_start;
			buff->to_addr = to_addr + delta;
			if (copy_to_user((char *)ioctl_param, buff, sizeof(struct address)))
			{
				pr_err("MVE_VMA new address write error\n");
				return -1;
			}
			vfree(buff);
		}
		printk(KERN_INFO "Got new addr as %lx\n", to_addr);

		// Remap VMA
		mmap_write_lock(mm);
		ret = my_mremap(ovma, to_addr);
		mmap_write_unlock(mm);
		return ret;
		
	case IOCTL_PROMOTE_VMA:
		// Create kthread

		regs = task_pt_regs(current);
		kp = (struct inp *)kmalloc(GFP_KERNEL, sizeof(struct inp));
		kp->sp = regs->sp;
		kp->mm = mm;
		printk("sp: %lx, mm: %p, MM: %p\n", kp->sp, kp->mm, mm);
		kthread_task = kthread_create(promote_pages, (void *)(kp), "promote-pages");
		if(IS_ERR(kthread_task)){
			printk(KERN_ALERT "Couldn't create kernel thread!\n");
			return -EINVAL;
		}

		wake_up_process(kthread_task);
		printk("promoting 4KB pages to 2mb\n");
		return ret;
	case IOCTL_COMPACT_VMA:
		printk("compact VMA\n");
	    ip = (struct input*)vmalloc(sizeof(struct input)) ;
	    if(copy_from_user(ip,(char*)ioctl_param,sizeof(struct input))){
                pr_err("MVE_MERG_VMA address write error\n");
                return ret;
            }
	    vma_addr = ip->addr;
	    length = ip->length;
	    buff = ip->buff;
	    temp.from_addr = vma_addr;
	    temp.to_addr = vma_addr;
	    printk("vma address:%lx, length:%u, buff:%lx\n",vma_addr,length,(unsigned long)buff);
	    //populate old to new address mapping in user buffer.
	    //number of entries in this buffer is equal to the number of 
	    //virtual pages in vma address range
	    //index of moved addr in mapping table is , index = (addr-vma_address)>>12
		printk("Userbuffer addr 1: %lx\n", (unsigned long)buff);
		compact_vma(current->mm, vma_addr, length, buff);

	    // index = (vma_addr-vma_addr)>>12;
	    // if(copy_to_user((struct address *)buff+index, &temp, sizeof(struct address))){
	    //     pr_err("COMPACT VMA read error\n");
		// return ret;
	    // } 
	    vfree(ip);
            return ret;
	}
	return ret;
}

static struct file_operations fops = {
	.read = device_read,
	.write = device_write,
	.unlocked_ioctl = device_ioctl,
	.open = device_open,
	.release = device_release,
};

static char *demo_devnode(struct device *dev, umode_t *mode)
{
	if (mode && dev->devt == MKDEV(major, 0))
		*mode = 0666;
	return NULL;
}


// Implement required logic
static ssize_t sysfs_show(struct kobject *kobj, struct kobj_attribute *attr,
						  char *buf)
{
	pr_info("kernel sysfs read success\n");
	return sprintf(buf, "%d", promote);
}

// Implement required logic
static ssize_t sysfs_store(struct kobject *kobj, struct kobj_attribute *attr,
						   const char *buf, size_t count)
{

	struct mm_struct *mm = current->mm;
	unsigned long sp = task_pt_regs(current)->sp;
	promote = 1;
	mmap_write_lock(mm);
	do_promote(mm, sp);
	mmap_write_unlock(mm);
	printk("kernel sysfs write success\n");
	promote = 0;
	
	return count;
}

static int break_at(struct vm_area_struct * vma, unsigned long addr){
	unsigned long page_size = PAGE_SIZE;
	void * new_page_addr;
	int err;
	struct page* new_page;
	unsigned long page_start, page_end;
	// char *ker_buff;
	unsigned long pfn;
	// int ret=0;

	for(int i = 0; i<512; i++){
		page_start = addr + i * page_size;
        page_end = page_start + page_size;

        // Allocate a new 4KB page
        new_page = alloc_pages(GFP_USER | __GFP_ZERO, 0);
        if (!new_page) {
			return -1;
            // Failed to allocate page
            break;
        }
		printk("Allocated new page\n");

        // Copy data from the huge page to the new page
		printk("Page start value: %c\n", *(char *)page_start);
        new_page_addr = page_address(new_page);
		// ker_buff = kmalloc(4096, GFP_KERNEL);
		// ret = copy_from_user(ker_buff, (void *)page_start, 4096);
		// if (ret)
		// {
		// 	printk("ret: %d", ret);
			
		// 	pr_err("huge page copy from user failed\n");
		// 	return -1;
		// }
		// printk("kern buff bit : %d\n", *(int *)ker_buff);
		// printk("bit: %c\n", )
		printk("page_address done\n");
        memcpy(new_page_addr, (void * ) page_start, page_size);

		// if (copy_to_user(new_page_addr, ker_buff, 4096))
		// {
		// 	pr_err("huge page copy fto user failed\n");
		// 	return -1;
		// }
		printk("memcpy done\n");

        // Remap the original VMA to the new page
		pfn = page_to_pfn(new_page);
		printk(KERN_INFO "remap_pfn_range(%lx, %lx, %lx, %lx, %lx, %lx)\n", vma->vm_start, vma->vm_end, page_start, pfn, page_size, (unsigned long)vma->vm_page_prot.pgprot);
        mmap_write_lock(vma->vm_mm);
		err = remap_pfn_range(vma, page_start, pfn, page_size, vma->vm_page_prot);
		mmap_write_unlock(vma->vm_mm);
        if (err) {
			printk(KERN_ALERT "Failed to remap page, %d\n", err);
            // Failed to remap page
			return -1;
        }
		printk("remap_pfn_range done\n");
        // Flush the TLB cache for the remapped page range
		__flush_tlb_all();
        // (vma, page_start, page_end);
	}
	
	return 0;
}

int is_pmd_huge_page(struct mm_struct *mm,unsigned long addr){
	pgd_t * pgd = pgd_offset(mm, addr);
	p4d_t * p4d = p4d_offset(pgd, addr);
	pud_t * pud = pud_offset(p4d, addr);
	pmd_t * pmd = pmd_offset(pud, addr);

	if(pmd && pmd_present(*pmd) && (pmd->pmd & _PAGE_PSE)){
		return 1;
	}
	else return 0;
}

static int __kprobes my_munmap(struct kprobe * p, struct pt_regs * reg){
	// struct vm_area_struct *vma, unsigned long addr, size_t len)
	// struct mm_struct * mm = (struct mm_struct *)reg->di;
	unsigned long addr = reg->di;
	size_t len = reg->si;
	struct vm_area_struct * vma = find_vma(current->mm, addr);
	// printk("munmap called with addr %lx and len %lx pid: %d vm flags:%lu\n", addr, len,current->pid, vma->vm_flags&VM_HUGEPAGE);
	if(vma->vm_flags & VM_HUGEPAGE){

		if(is_pmd_huge_page(current->mm, addr)){
			printk("Huge page unmapping function called with vma start: %lx and vma end: %lx\n", vma->vm_start, vma->vm_end);
			if((addr) % HUGE_PAGE_SIZE){
				if(break_at(vma, addr - ((addr) % HUGE_PAGE_SIZE) )){
					printk(KERN_ALERT "Failed to break at %lx\n", addr - ((addr) % HUGE_PAGE_SIZE));
				}
			}
			if((addr + len) % HUGE_PAGE_SIZE){
				// if(break_at(vma, addr + len - ((addr + len) % HUGE_PAGE_SIZE) )){
				// 	printk(KERN_ALERT "Failed to break at %lx\n", addr + len - ((addr + len ) % HUGE_PAGE_SIZE));
				// }
			}
		}
		else{
			printk("Not a huge page\n");
		}
	}
	return 0;
}


static struct kprobe kp;

int init_munmap_hook(void){
    int ret;
    printk(KERN_INFO "Setting the probe\n");
    memset(&kp, 0, sizeof(struct kprobe));
	kp.symbol_name = "__vm_munmap";
	kp.pre_handler = my_munmap;
	ret = register_kprobe(&kp);
	if(ret < 0){
		printk(KERN_ALERT "Failed to register kprobe, returnded %d\n", ret);
		return ret;
	}
    printk(KERN_INFO "Planted kprobe at %lx\n", (unsigned long)kp.addr);
	return 0;
}

int init_module(void)
{
	int err;
	magic = (unsigned long (*)(const char *))lookup_kallsyms_lookup_name();
	if(!magic){
		printk(KERN_ALERT "Couldn't get address for kallsyms_lookup_name!\n");
		return -EINVAL;
	}
	my_copy_vma = (struct vm_area_struct* (*)(struct vm_area_struct **, unsigned long , unsigned long , pgoff_t , bool *))magic("copy_vma");
	my_move_page_tables = (unsigned long (*) (struct vm_area_struct * , unsigned long ,  struct vm_area_struct * , unsigned long , unsigned long , bool))magic("move_page_tables");
	my_do_munmap = (int (*) (struct mm_struct *, unsigned long, size_t, struct list_head *uf))magic("do_munmap");
	
	if(!my_copy_vma || !my_move_page_tables || !my_do_munmap){
		printk(KERN_ALERT "Couldn't get the addresses for functions\n");
		return -EINVAL;
	}
	kthread_task = NULL;
	if(init_munmap_hook()){
		printk(KERN_ALERT "Failed to init munmap hook\n");
		return -EINVAL;
	}
	printk(KERN_INFO "Hello kernel\n");
	major = register_chrdev(0, DEVNAME, &fops);
	err = major;
	if (err < 0)
	{
		printk(KERN_ALERT "Registering char device failed with %d\n", major);
		goto error_regdev;
	}

	demo_class = class_create(THIS_MODULE, DEVNAME);
	err = PTR_ERR(demo_class);
	if (IS_ERR(demo_class))
		goto error_class;

	demo_class->devnode = demo_devnode;

	demo_device = device_create(demo_class, NULL,
								MKDEV(major, 0),
								NULL, DEVNAME);
	err = PTR_ERR(demo_device);
	if (IS_ERR(demo_device))
		goto error_device;

	printk(KERN_INFO "I was assigned major number %d. To talk to\n", major);
	atomic_set(&device_opened, 0);

	cs614_kobject = kobject_create_and_add("kobject_cs614", kernel_kobj);

	if (!cs614_kobject)
		return -ENOMEM;

	sysfs_attr.attr.name = "promote";
	sysfs_attr.attr.mode = 0666;
	sysfs_attr.show = sysfs_show;
	sysfs_attr.store = sysfs_store;

	err = sysfs_create_file(cs614_kobject, &(sysfs_attr.attr));
	if (err)
	{
		pr_info("sysfs exists:");
		goto r_sysfs;
	}
	return 0;
r_sysfs:
	kobject_put(cs614_kobject);
	sysfs_remove_file(kernel_kobj, &sysfs_attr.attr);
error_device:
	class_destroy(demo_class);
error_class:
	unregister_chrdev(major, DEVNAME);
error_regdev:
	return err;
}

void cleanup_module(void)
{
	if(kthread_task != NULL){
		kthread_stop(kthread_task);
	}
    unregister_kprobe(&kp);
	device_destroy(demo_class, MKDEV(major, 0));
	class_destroy(demo_class);
	unregister_chrdev(major, DEVNAME);
	kobject_put(cs614_kobject);
	sysfs_remove_file(kernel_kobj, &sysfs_attr.attr);
	printk(KERN_INFO "Goodbye kernel\n");
}

MODULE_AUTHOR("cs614");
MODULE_LICENSE("GPL");
MODULE_DESCRIPTION("assignment2");
